evaluate_task_response:
  description: >
    Evaluate the agent's response to ensure it meets the required standards of accuracy, clarity, professionalism, and adherence to task-specific instructions. Use the "last_answer" provided to assess quality, appropriateness, and alignment with any relevant guidelines or FAQ provided in the task description. Approve only if the response fully meets the quality standards, and provide consistent, constructive feedback if necessary.

    TASK DESCRIPTION
    ----------------
    {task_description}

    LAST FEEDBACK
    -----------------------
    {last_feedback}

    ANSWER TO EVALUATE
    -----------------------
    {last_answer}

    EVALUATION CRITERIA
    --------------------
    Use the following criteria to assess the response, applying these standards to any specific task requirements included in the task description:

    - **Relevance to Task Requirements**: Does the response accurately address the task requirements as outlined in the task description? For example, if the task involves a customer query, does the response resolve the query effectively? If it’s a summarization, does it capture key points without losing essential information?
    
    - **Completeness and Accuracy**: Ensure the response fully addresses all aspects of the task. For translation, this would mean retaining the original meaning and tone; for a customer service response, it means resolving the issue comprehensively; and for technical tasks, it involves meeting detailed requirements precisely.

    - **Clarity and Conciseness**: Is the response clear, direct, and free from unnecessary complexity? Responses should be accessible and easy to understand. Technical jargon should be avoided unless necessary, and any specialized terminology should be used correctly.

    - **Professional Tone and Appropriateness**: Check if the tone aligns with task requirements. Customer service responses should be empathetic and courteous, translations should maintain the original tone, and responses in professional tasks should be clear and respectful.

    - **Adherence to Any Guidelines**: If the task description includes specific guidelines, verify that the agent referred to or correctly incorporated relevant information. This applies to customer support, where standard protocols may be needed, or other tasks where adherence to specific instructions ensures consistency.

    - **Effective Use of Feedback**: If feedback is available from previous evaluations, assess whether the agent has integrated this feedback effectively to improve the quality of their response. Consistent feedback should guide agents toward continuous improvement, applying lessons learned across similar tasks. Make sure you don't repeat the last feedback if it has been addressed in the answer.

    Be relatively strict in evaluation. Approve responses only if they meet all relevant criteria. Be especially strict when there has been no previous feedback given.
    If there is feedback from evaluators, use it to make sure that your assessment is as reliable as possible.

  expected_output: >
    Return a JSON object with:
    - `feedback` (string): Constructive, consistent feedback for the agent on how to improve accuracy, clarity, tone, or alignment with task-specific guidelines. If the response did not meet quality standards, provide actionable recommendations. Feedback should remain consistent across evaluations to help agents develop a reliable approach to improvement.
    - `approved` (boolean): True if the response meets high-quality standards in all criteria, otherwise False.
    
  agent: evaluation_agent

select_evaluators_for_task:
  description: >
    Select the most relevant evaluators based on the task description to ensure the response receives comprehensive and appropriate feedback. Use the task description to assess which evaluators (e.g., Tone of Voice, Translation Accuracy) are most suitable for evaluating key aspects of the task.

    TASK DESCRIPTION
    ----------------
    {task_description}

    EVALUATOR OPTIONS
    -----------------
    You have access to multiple evaluators, each specialized in a specific aspect, such as Tone of Voice, Translation Accuracy, Completeness, and more. Carefully assess each option and choose only those evaluators that can provide meaningful insights based on the task description:
    {evaluator_options}

    SELECTION CRITERIA
    -------------------
    - **Relevance to Task Requirements**: Does the evaluator’s expertise directly relate to the task?
    - **Completeness and Depth**: Ensure selected evaluators provide feedback on all critical aspects of the task.
    - **Task-Specific Guidelines**: Select evaluators who can best ensure the guidelines are met.
    - **Consistency and Development Potential**: Choose evaluators who contribute to consistent feedback across similar tasks.

    Be selective and ensure comprehensive, relevant feedback.

  expected_output: >
    Return a JSON object with:
    - 'rationale' (string): A brief explanation for why each evaluator was chosen.
    - 'selected_evaluators' (list of strings): Names of the chosen evaluators who will assess the response.

create_inputs_for_evaluators:
  description: >
    Generate appropriate input messages based on the task requirements and the prompt templates of the selected evaluators. Use the task description to understand the context of the task and create specific inputs that will lead to accurate evaluations by the chosen evaluators.

    TASK DESCRIPTION
    ----------------
    {task_description}

    SELECTED EVALUATORS
    --------------------
    {selected_evaluators}

    PROMPT TEMPLATES
    -----------------
    Use the following evaluator prompt templates to guide the creation of appropriate input messages:
    {prompt_templates}

    INPUT MESSAGE REQUIREMENTS
    --------------------------
    - Ensure that the input messages are realistic and align with the task description.
    - Input messages should include clear instructions for completing the task (e.g., generating a response, translating text, writing an email) rather than merely asking for evaluation of an answer.
    - If you cannot think of a valid input message for an evaluator, exclude that evaluator from the final selection.

  expected_output: >
    Return a JSON object with:
    - 'selected_evaluators' (list of strings): Names of the evaluators who will assess the response.
    - 'inputs' (list of strings): appropriate input messages based on the task given to get the most accurate response out of the evaluator.



select_best_answer_task:
  description: >
    Select the best answer from the list of answers provided for the task below. Provide a clear rationale explaining why you chose the best answer.

    TASK DESCRIPTION
    ----------------
    {task_description}

    ANSWER ITERATIONS
    -----------------
    {answers}

    SELECTION CRITERIA
    -------------------
    - Evaluate how well each answer addresses the task requirements described above.
    - Focus on clarity, relevance, and overall quality of the answers.
    - Provide a detailed explanation for your decision, ensuring that your rationale is easy to understand and aligns with the task description.

  expected_output: >
    Return a JSON object with:
    - `rationale` (string): A detailed explanation for why the selected answer is the best.
    - `final_decision` (string): The best answer chosen after analyzing all iterations.

  agent: best_answer_agent