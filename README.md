# How to evaluate and monitor LLM deployments in real-time?

This is a repository for my work about the experiments with the Evaluator Library and the Supervisory Multi-Agent System. Data and scripts for the former are in the discrimination_results folder and files for the agent system are in the supervisory_agent folder, both folders include an extra README. Final prompts for evaluators and prompt variations for the experiments are in the prompts folder.
 
